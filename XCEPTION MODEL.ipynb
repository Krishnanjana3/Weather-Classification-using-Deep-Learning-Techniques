{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b4ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\s\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 5505 images belonging to 11 classes.\n",
      "Found 1372 images belonging to 11 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\s\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\s\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\s\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/29\n",
      "WARNING:tensorflow:From C:\\Users\\s\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\s\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "172/172 [==============================] - 1206s 7s/step - loss: 0.7228 - accuracy: 0.7643 - val_loss: 0.4602 - val_accuracy: 0.8460\n",
      "Epoch 2/29\n",
      "172/172 [==============================] - 1132s 7s/step - loss: 0.3747 - accuracy: 0.8714 - val_loss: 0.4717 - val_accuracy: 0.8438\n",
      "Epoch 3/29\n",
      "172/172 [==============================] - 1129s 7s/step - loss: 0.2766 - accuracy: 0.9059 - val_loss: 0.4685 - val_accuracy: 0.8497\n",
      "Epoch 4/29\n",
      "172/172 [==============================] - 1122s 7s/step - loss: 0.2088 - accuracy: 0.9340 - val_loss: 0.4696 - val_accuracy: 0.8557\n",
      "Epoch 5/29\n",
      "172/172 [==============================] - 1121s 7s/step - loss: 0.1576 - accuracy: 0.9540 - val_loss: 0.4598 - val_accuracy: 0.8601\n",
      "Epoch 6/29\n",
      "172/172 [==============================] - 1694s 10s/step - loss: 0.1339 - accuracy: 0.9560 - val_loss: 0.4514 - val_accuracy: 0.8638\n",
      "Epoch 7/29\n",
      "172/172 [==============================] - 1129s 7s/step - loss: 0.1019 - accuracy: 0.9726 - val_loss: 0.4633 - val_accuracy: 0.8586\n",
      "Epoch 8/29\n",
      "172/172 [==============================] - 1135s 7s/step - loss: 0.1317 - accuracy: 0.9629 - val_loss: 0.4969 - val_accuracy: 0.8631\n",
      "Epoch 9/29\n",
      "172/172 [==============================] - 1154s 7s/step - loss: 0.0672 - accuracy: 0.9832 - val_loss: 0.4802 - val_accuracy: 0.8676\n",
      "Epoch 10/29\n",
      "172/172 [==============================] - 1123s 7s/step - loss: 0.0526 - accuracy: 0.9885 - val_loss: 0.5078 - val_accuracy: 0.8601\n",
      "Epoch 11/29\n",
      "172/172 [==============================] - 1122s 7s/step - loss: 0.0391 - accuracy: 0.9945 - val_loss: 0.5072 - val_accuracy: 0.8690\n",
      "Epoch 12/29\n",
      "172/172 [==============================] - 1117s 7s/step - loss: 0.0312 - accuracy: 0.9952 - val_loss: 0.5375 - val_accuracy: 0.8646\n",
      "Epoch 13/29\n",
      "172/172 [==============================] - 20426s 119s/step - loss: 0.0260 - accuracy: 0.9965 - val_loss: 0.5640 - val_accuracy: 0.8646\n",
      "Epoch 14/29\n",
      "172/172 [==============================] - 1125s 7s/step - loss: 0.0201 - accuracy: 0.9980 - val_loss: 0.6312 - val_accuracy: 0.8564\n",
      "Epoch 15/29\n",
      "172/172 [==============================] - 1115s 6s/step - loss: 0.0206 - accuracy: 0.9976 - val_loss: 0.5865 - val_accuracy: 0.8601\n",
      "Epoch 16/29\n",
      "172/172 [==============================] - 1117s 6s/step - loss: 0.0273 - accuracy: 0.9945 - val_loss: 0.5860 - val_accuracy: 0.8705\n",
      "Epoch 17/29\n",
      "172/172 [==============================] - 1116s 6s/step - loss: 0.0152 - accuracy: 0.9982 - val_loss: 0.5839 - val_accuracy: 0.8705\n",
      "Epoch 18/29\n",
      "172/172 [==============================] - 1115s 6s/step - loss: 0.0120 - accuracy: 0.9985 - val_loss: 0.6053 - val_accuracy: 0.8676\n",
      "Epoch 19/29\n",
      "172/172 [==============================] - 1116s 6s/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.6623 - val_accuracy: 0.8594\n",
      "Epoch 20/29\n",
      "172/172 [==============================] - 1114s 6s/step - loss: 0.0103 - accuracy: 0.9987 - val_loss: 0.6480 - val_accuracy: 0.8690\n",
      "Epoch 21/29\n",
      "172/172 [==============================] - 1115s 6s/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.6289 - val_accuracy: 0.8705\n",
      "Epoch 22/29\n",
      "172/172 [==============================] - 1115s 6s/step - loss: 0.0141 - accuracy: 0.9967 - val_loss: 0.7009 - val_accuracy: 0.8586\n",
      "Epoch 23/29\n",
      "172/172 [==============================] - 9942s 58s/step - loss: 0.0161 - accuracy: 0.9969 - val_loss: 0.9032 - val_accuracy: 0.8400\n",
      "Epoch 24/29\n",
      "172/172 [==============================] - 1154s 7s/step - loss: 0.0176 - accuracy: 0.9954 - val_loss: 0.6614 - val_accuracy: 0.8653\n",
      "Epoch 25/29\n",
      "172/172 [==============================] - 1144s 7s/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 0.6705 - val_accuracy: 0.8683\n",
      "Epoch 26/29\n",
      "172/172 [==============================] - 1156s 7s/step - loss: 0.0052 - accuracy: 0.9995 - val_loss: 0.7027 - val_accuracy: 0.8609\n",
      "Epoch 27/29\n",
      "172/172 [==============================] - 1135s 7s/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.7791 - val_accuracy: 0.8638\n",
      "Epoch 28/29\n",
      "172/172 [==============================] - 1132s 7s/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.7498 - val_accuracy: 0.8676\n",
      "Epoch 29/29\n",
      "172/172 [==============================] - 1827s 11s/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.7282 - val_accuracy: 0.8609\n",
      "43/43 [==============================] - 300s 7s/step - loss: 0.7357 - accuracy: 0.8564\n",
      "Validation Loss: 0.7357066869735718\n",
      "Validation Accuracy: 0.8564140200614929\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 32\n",
    "epochs = 29\n",
    "image_size = (299, 299)  # Image size expected by Xception\n",
    "\n",
    "np.random.seed(20)\n",
    "random.seed(20)\n",
    "tf.random.set_seed(20)\n",
    "\n",
    "# Define data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\dataset',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # use 'categorical' for multiple classes\n",
    "    subset='training',\n",
    "    shuffle=True  # Ensure data is shuffled\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\dataset',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # use 'categorical' for multiple classes\n",
    "    subset='validation',\n",
    "    shuffle=False  # No need to shuffle validation data\n",
    ")\n",
    "\n",
    "# Load Xception pre-trained on ImageNet\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)  # Add more dense layers if needed\n",
    "predictions = Dense(11, activation='softmax')(x)  # Adjust output neurons based on your problem (11 classes)\n",
    "\n",
    "# Combine base model and custom head\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', # use 'categorical_crossentropy' for multiple classes\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model with verbose logging and time callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    verbose=1  # Ensure verbose output to monitor progress\n",
    ")\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8976d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('Xception_model.h5')\n",
    "#save history\n",
    "import pickle\n",
    "with open('Xception_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cc0d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
