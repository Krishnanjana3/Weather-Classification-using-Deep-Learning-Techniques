{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76803016",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 5505 images belonging to 11 classes.\n",
      "Found 1372 images belonging to 11 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 16s 0us/step\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "172/172 [==============================] - 2963s 17s/step - loss: 1.5688 - accuracy: 0.4972 - val_loss: 1.1570 - val_accuracy: 0.6213\n",
      "Epoch 2/30\n",
      "172/172 [==============================] - 2649s 15s/step - loss: 1.0237 - accuracy: 0.6644 - val_loss: 0.9009 - val_accuracy: 0.7217\n",
      "Epoch 3/30\n",
      "172/172 [==============================] - 5817s 34s/step - loss: 0.8533 - accuracy: 0.7148 - val_loss: 0.7893 - val_accuracy: 0.7284\n",
      "Epoch 4/30\n",
      "172/172 [==============================] - 7873s 46s/step - loss: 0.7521 - accuracy: 0.7464 - val_loss: 0.7376 - val_accuracy: 0.7604\n",
      "Epoch 5/30\n",
      "172/172 [==============================] - 2748s 16s/step - loss: 0.6956 - accuracy: 0.7661 - val_loss: 0.7063 - val_accuracy: 0.7619\n",
      "Epoch 6/30\n",
      "172/172 [==============================] - 2646s 15s/step - loss: 0.6500 - accuracy: 0.7733 - val_loss: 0.6812 - val_accuracy: 0.7708\n",
      "Epoch 7/30\n",
      "172/172 [==============================] - 1344s 8s/step - loss: 0.6347 - accuracy: 0.7829 - val_loss: 0.6324 - val_accuracy: 0.7835\n",
      "Epoch 8/30\n",
      "172/172 [==============================] - 1342s 8s/step - loss: 0.5818 - accuracy: 0.8019 - val_loss: 0.6363 - val_accuracy: 0.7842\n",
      "Epoch 9/30\n",
      "172/172 [==============================] - 1338s 8s/step - loss: 0.5584 - accuracy: 0.8096 - val_loss: 0.6342 - val_accuracy: 0.7850\n",
      "Epoch 10/30\n",
      "172/172 [==============================] - 1332s 8s/step - loss: 0.5419 - accuracy: 0.8131 - val_loss: 0.5885 - val_accuracy: 0.8043\n",
      "Epoch 11/30\n",
      "172/172 [==============================] - 1345s 8s/step - loss: 0.5200 - accuracy: 0.8220 - val_loss: 0.6177 - val_accuracy: 0.7894\n",
      "Epoch 12/30\n",
      "172/172 [==============================] - 1330s 8s/step - loss: 0.4986 - accuracy: 0.8268 - val_loss: 0.5898 - val_accuracy: 0.7932\n",
      "Epoch 13/30\n",
      "172/172 [==============================] - 1325s 8s/step - loss: 0.4737 - accuracy: 0.8365 - val_loss: 0.5804 - val_accuracy: 0.8051\n",
      "Epoch 14/30\n",
      "172/172 [==============================] - 1341s 8s/step - loss: 0.4665 - accuracy: 0.8409 - val_loss: 0.5812 - val_accuracy: 0.7954\n",
      "Epoch 15/30\n",
      "172/172 [==============================] - 1341s 8s/step - loss: 0.4494 - accuracy: 0.8482 - val_loss: 0.5600 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "172/172 [==============================] - 1323s 8s/step - loss: 0.4434 - accuracy: 0.8471 - val_loss: 0.5642 - val_accuracy: 0.8162\n",
      "Epoch 17/30\n",
      "172/172 [==============================] - 1322s 8s/step - loss: 0.4251 - accuracy: 0.8568 - val_loss: 0.5474 - val_accuracy: 0.8147\n",
      "Epoch 18/30\n",
      "172/172 [==============================] - 1320s 8s/step - loss: 0.4086 - accuracy: 0.8641 - val_loss: 0.5559 - val_accuracy: 0.8199\n",
      "Epoch 19/30\n",
      "172/172 [==============================] - 1321s 8s/step - loss: 0.3984 - accuracy: 0.8650 - val_loss: 0.5633 - val_accuracy: 0.8088\n",
      "Epoch 20/30\n",
      "172/172 [==============================] - 1322s 8s/step - loss: 0.4208 - accuracy: 0.8597 - val_loss: 0.5418 - val_accuracy: 0.8140\n",
      "Epoch 21/30\n",
      "172/172 [==============================] - 1322s 8s/step - loss: 0.3795 - accuracy: 0.8741 - val_loss: 0.5500 - val_accuracy: 0.8073\n",
      "Epoch 22/30\n",
      "172/172 [==============================] - 1336s 8s/step - loss: 0.3769 - accuracy: 0.8726 - val_loss: 0.5339 - val_accuracy: 0.8214\n",
      "Epoch 23/30\n",
      "172/172 [==============================] - 1321s 8s/step - loss: 0.3603 - accuracy: 0.8827 - val_loss: 0.5346 - val_accuracy: 0.8170\n",
      "Epoch 24/30\n",
      "172/172 [==============================] - 1380s 8s/step - loss: 0.3529 - accuracy: 0.8867 - val_loss: 0.5468 - val_accuracy: 0.8132\n",
      "Epoch 25/30\n",
      "172/172 [==============================] - 1369s 8s/step - loss: 0.3434 - accuracy: 0.8851 - val_loss: 0.5477 - val_accuracy: 0.8222\n",
      "Epoch 26/30\n",
      "172/172 [==============================] - 1328s 8s/step - loss: 0.3377 - accuracy: 0.8882 - val_loss: 0.5413 - val_accuracy: 0.8155\n",
      "Epoch 27/30\n",
      "172/172 [==============================] - 1318s 8s/step - loss: 0.3289 - accuracy: 0.8882 - val_loss: 0.5448 - val_accuracy: 0.8207\n",
      "Epoch 28/30\n",
      "172/172 [==============================] - 2615s 15s/step - loss: 0.3247 - accuracy: 0.8937 - val_loss: 0.5549 - val_accuracy: 0.8192\n",
      "Epoch 29/30\n",
      "172/172 [==============================] - 3052s 18s/step - loss: 0.3128 - accuracy: 0.8982 - val_loss: 0.5457 - val_accuracy: 0.8281\n",
      "Epoch 30/30\n",
      "172/172 [==============================] - 3057s 18s/step - loss: 0.3343 - accuracy: 0.8896 - val_loss: 0.6405 - val_accuracy: 0.7909\n",
      "43/43 [==============================] - 614s 14s/step - loss: 0.6381 - accuracy: 0.7915\n",
      "Validation Loss: 0.6380566954612732\n",
      "Validation Accuracy: 0.7915452122688293\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "image_size = (224, 224) # Image size expected by VGG16\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define data generators for training, validation, and test\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\Grapes\\Downloads\\dataset-1\\dataset',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', # use 'categorical' for multiple classes\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\Grapes\\Downloads\\dataset-1\\dataset',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', # use 'categorical' for multiple classes\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load VGG16 pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x) # Add more dense layers if needed\n",
    "predictions = Dense(11, activation='softmax')(x) # Adjust output neurons based on your problem (11 classes)\n",
    "\n",
    "# Combine base model and custom head\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', # use 'categorical_crossentropy' for multiple classes\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09383ea8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 5505 images belonging to 11 classes.\n",
      "Found 1372 images belonging to 11 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/29\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "172/172 [==============================] - 1393s 8s/step - loss: 1.5688 - accuracy: 0.4972 - val_loss: 1.1570 - val_accuracy: 0.6213\n",
      "Epoch 2/29\n",
      "172/172 [==============================] - 1285s 7s/step - loss: 1.0237 - accuracy: 0.6644 - val_loss: 0.9009 - val_accuracy: 0.7217\n",
      "Epoch 3/29\n",
      "172/172 [==============================] - 1290s 8s/step - loss: 0.8533 - accuracy: 0.7148 - val_loss: 0.7893 - val_accuracy: 0.7284\n",
      "Epoch 4/29\n",
      "172/172 [==============================] - 1288s 7s/step - loss: 0.7521 - accuracy: 0.7464 - val_loss: 0.7376 - val_accuracy: 0.7604\n",
      "Epoch 5/29\n",
      "172/172 [==============================] - 8144s 48s/step - loss: 0.6956 - accuracy: 0.7661 - val_loss: 0.7063 - val_accuracy: 0.7619\n",
      "Epoch 6/29\n",
      "172/172 [==============================] - 1313s 8s/step - loss: 0.6500 - accuracy: 0.7733 - val_loss: 0.6812 - val_accuracy: 0.7708\n",
      "Epoch 7/29\n",
      "172/172 [==============================] - 1309s 8s/step - loss: 0.6347 - accuracy: 0.7829 - val_loss: 0.6324 - val_accuracy: 0.7835\n",
      "Epoch 8/29\n",
      "172/172 [==============================] - 2691s 16s/step - loss: 0.5818 - accuracy: 0.8019 - val_loss: 0.6363 - val_accuracy: 0.7842\n",
      "Epoch 9/29\n",
      "172/172 [==============================] - 2939s 17s/step - loss: 0.5584 - accuracy: 0.8096 - val_loss: 0.6342 - val_accuracy: 0.7850\n",
      "Epoch 10/29\n",
      "172/172 [==============================] - 2977s 17s/step - loss: 0.5419 - accuracy: 0.8131 - val_loss: 0.5885 - val_accuracy: 0.8043\n",
      "Epoch 11/29\n",
      "172/172 [==============================] - 1305s 8s/step - loss: 0.5200 - accuracy: 0.8220 - val_loss: 0.6177 - val_accuracy: 0.7894\n",
      "Epoch 12/29\n",
      "172/172 [==============================] - 1282s 7s/step - loss: 0.4986 - accuracy: 0.8268 - val_loss: 0.5898 - val_accuracy: 0.7932\n",
      "Epoch 13/29\n",
      "172/172 [==============================] - 1291s 8s/step - loss: 0.4737 - accuracy: 0.8365 - val_loss: 0.5804 - val_accuracy: 0.8051\n",
      "Epoch 14/29\n",
      "172/172 [==============================] - 1284s 7s/step - loss: 0.4665 - accuracy: 0.8409 - val_loss: 0.5812 - val_accuracy: 0.7954\n",
      "Epoch 15/29\n",
      "172/172 [==============================] - 1286s 7s/step - loss: 0.4494 - accuracy: 0.8482 - val_loss: 0.5600 - val_accuracy: 0.8125\n",
      "Epoch 16/29\n",
      "172/172 [==============================] - 1281s 7s/step - loss: 0.4434 - accuracy: 0.8471 - val_loss: 0.5642 - val_accuracy: 0.8162\n",
      "Epoch 17/29\n",
      "172/172 [==============================] - 1281s 7s/step - loss: 0.4251 - accuracy: 0.8568 - val_loss: 0.5474 - val_accuracy: 0.8147\n",
      "Epoch 18/29\n",
      "172/172 [==============================] - 1285s 7s/step - loss: 0.4086 - accuracy: 0.8641 - val_loss: 0.5559 - val_accuracy: 0.8199\n",
      "Epoch 19/29\n",
      "172/172 [==============================] - 1281s 7s/step - loss: 0.3984 - accuracy: 0.8650 - val_loss: 0.5633 - val_accuracy: 0.8088\n",
      "Epoch 20/29\n",
      "172/172 [==============================] - 1284s 7s/step - loss: 0.4208 - accuracy: 0.8597 - val_loss: 0.5418 - val_accuracy: 0.8140\n",
      "Epoch 21/29\n",
      "172/172 [==============================] - 1289s 8s/step - loss: 0.3795 - accuracy: 0.8741 - val_loss: 0.5500 - val_accuracy: 0.8073\n",
      "Epoch 22/29\n",
      "172/172 [==============================] - 1279s 7s/step - loss: 0.3769 - accuracy: 0.8726 - val_loss: 0.5339 - val_accuracy: 0.8214\n",
      "Epoch 23/29\n",
      "172/172 [==============================] - 1276s 7s/step - loss: 0.3603 - accuracy: 0.8827 - val_loss: 0.5346 - val_accuracy: 0.8170\n",
      "Epoch 24/29\n",
      "172/172 [==============================] - 1283s 7s/step - loss: 0.3529 - accuracy: 0.8867 - val_loss: 0.5468 - val_accuracy: 0.8132\n",
      "Epoch 25/29\n",
      "172/172 [==============================] - 1286s 7s/step - loss: 0.3434 - accuracy: 0.8851 - val_loss: 0.5477 - val_accuracy: 0.8222\n",
      "Epoch 26/29\n",
      "172/172 [==============================] - 1294s 8s/step - loss: 0.3377 - accuracy: 0.8882 - val_loss: 0.5413 - val_accuracy: 0.8155\n",
      "Epoch 27/29\n",
      "172/172 [==============================] - 1304s 8s/step - loss: 0.3289 - accuracy: 0.8882 - val_loss: 0.5448 - val_accuracy: 0.8207\n",
      "Epoch 28/29\n",
      "172/172 [==============================] - 1289s 8s/step - loss: 0.3247 - accuracy: 0.8937 - val_loss: 0.5549 - val_accuracy: 0.8192\n",
      "Epoch 29/29\n",
      "172/172 [==============================] - 1283s 7s/step - loss: 0.3128 - accuracy: 0.8982 - val_loss: 0.5457 - val_accuracy: 0.8281\n",
      "43/43 [==============================] - 257s 6s/step - loss: 0.5396 - accuracy: 0.8309\n",
      "Validation Loss: 0.5395508408546448\n",
      "Validation Accuracy: 0.8309037685394287\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 32\n",
    "epochs = 29\n",
    "image_size = (224, 224) # Image size expected by VGG16\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Define data generators for training, validation, and test\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\Grapes\\Downloads\\dataset-1\\dataset',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', # use 'categorical' for multiple classes\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\Grapes\\Downloads\\dataset-1\\dataset',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical', # use 'categorical' for multiple classes\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load VGG16 pre-trained on ImageNet\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x) # Add more dense layers if needed\n",
    "predictions = Dense(11, activation='softmax')(x) # Adjust output neurons based on your problem (11 classes)\n",
    "\n",
    "# Combine base model and custom head\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze layers in the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', # use 'categorical_crossentropy' for multiple classes\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation set\n",
    "loss, accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Loss:\", loss)\n",
    "print(\"Validation Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7993fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Grapes\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('Vgg16_model.h5')\n",
    "\n",
    "#save history\n",
    "import pickle\n",
    "with open('Vgg16_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38a410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
